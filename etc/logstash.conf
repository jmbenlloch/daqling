# DAQling Logstash configuration for creating a 
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  beats {
    port => 5044
  }
}
filter {
  grok {
    break_on_match => false
    match => {"message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{WORD:daq.log.thread}\] \[%{WORD:daq.log.source}\] \[%{WORD:daq.log.level}\] \[%{DATA:daq.line}\] \[%{DATA:daq.method}\]  %{GREEDYDATA:daq.message}"}
    match => {"[log][file][path]" => "s*\/%{WORD:daq.component}-%{WORD:daq.user}"}
  }
  date {
    match => ["timestamp", "YYYY-MM-dd HH:mm:ss.SSS"]
    target => "@timestamp"
    remove_field => ["timestamp"]
  }
}
output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
}
